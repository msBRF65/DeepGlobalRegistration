diff --git a/core/deep_global_registration.py b/core/deep_global_registration.py
index f848d91..fd76ea3 100644
--- a/core/deep_global_registration.py
+++ b/core/deep_global_registration.py
@@ -30,19 +30,19 @@ def registration_ransac_based_on_feature_matching(pcd0, pcd1, feats0, feats1,
                                                   distance_threshold, num_iterations):
   assert feats0.shape[1] == feats1.shape[1]
 
-  source_feat = o3d.registration.Feature()
+  source_feat = o3d.pipelines.registration.Feature()
   source_feat.resize(feats0.shape[1], len(feats0))
   source_feat.data = feats0.astype('d').transpose()
 
-  target_feat = o3d.registration.Feature()
+  target_feat = o3d.pipelines.registration.Feature()
   target_feat.resize(feats1.shape[1], len(feats1))
   target_feat.data = feats1.astype('d').transpose()
 
-  result = o3d.registration.registration_ransac_based_on_feature_matching(
+  result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
       pcd0, pcd1, source_feat, target_feat, distance_threshold,
-      o3d.registration.TransformationEstimationPointToPoint(False), 4,
-      [o3d.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
-      o3d.registration.RANSACConvergenceCriteria(num_iterations, 1000))
+      o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 4,
+      [o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
+      o3d.pipelines.registration.RANSACConvergenceCriteria(num_iterations, 1000))
 
   return result.transformation
 
@@ -52,10 +52,10 @@ def registration_ransac_based_on_correspondence(pcd0, pcd1, idx0, idx1,
   corres = np.stack((idx0, idx1), axis=1)
   corres = o3d.utility.Vector2iVector(corres)
 
-  result = o3d.registration.registration_ransac_based_on_correspondence(
+  result = o3d.pipelines.registration.registration_ransac_based_on_correspondence(
       pcd0, pcd1, corres, distance_threshold,
-      o3d.registration.TransformationEstimationPointToPoint(False), 4,
-      o3d.registration.RANSACConvergenceCriteria(4000000, num_iterations))
+      o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 4,
+      o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, num_iterations))
 
   return result.transformation
 
@@ -146,21 +146,23 @@ class DeepGlobalRegistration:
     # Voxelization:
     # Maintain double type for xyz to improve numerical accuracy in quantization
     sel = ME.utils.sparse_quantize(xyz / self.voxel_size, return_index=True)
-    npts = len(sel)
+    npts = len(sel[1])
 
-    xyz = torch.from_numpy(xyz[sel])
+    xyz = torch.from_numpy(xyz[sel[1]])
 
     # ME standard batch coordinates
     coords = ME.utils.batched_coordinates([torch.floor(xyz / self.voxel_size).int()])
     feats = torch.ones(npts, 1)
 
+    print(xyz.shape)
+    print()
     return xyz.float(), coords, feats
 
   def fcgf_feature_extraction(self, feats, coords):
     '''
     Step 1: extract fast and accurate FCGF feature per point
     '''
-    sinput = ME.SparseTensor(feats, coords=coords).to(self.device)
+    sinput = ME.SparseTensor(feats.to(self.device), coordinates=coords.to(self.device))
 
     return self.fcgf_model(sinput).F
 
@@ -207,7 +209,7 @@ class DeepGlobalRegistration:
     '''
     Step 4: predict inlier likelihood
     '''
-    sinput = ME.SparseTensor(inlier_feats, coords=coords).to(self.device)
+    sinput = ME.SparseTensor(inlier_feats.to(self.device), coordinates=coords.to(self.device))
     soutput = self.inlier_model(sinput)
 
     return soutput.F
@@ -311,9 +313,9 @@ class DeepGlobalRegistration:
       print(f'=> Safeguard takes {safeguard_time:.2} s')
 
     if self.use_icp:
-      T = o3d.registration.registration_icp(
+      T = o3d.pipelines.registration.registration_icp(
           make_open3d_point_cloud(xyz0),
           make_open3d_point_cloud(xyz1), self.voxel_size * 2, T,
-          o3d.registration.TransformationEstimationPointToPoint()).transformation
+          o3d.pipelines.registration.TransformationEstimationPointToPoint()).transformation
 
     return T
diff --git a/core/trainer.py b/core/trainer.py
index b8ae434..4d157b3 100644
--- a/core/trainer.py
+++ b/core/trainer.py
@@ -214,8 +214,8 @@ class WeightedProcrustesTrainer:
 
         # Inlier prediction with 6D ConvNet
         inlier_timer.tic()
-        reg_sinput = ME.SparseTensor(reg_feats.contiguous(),
-                                     coords=reg_coords.int()).to(self.device)
+        reg_sinput = ME.SparseTensor(reg_feats.contiguous().to(self.device),
+                                     coordinates=reg_coords.int().to(self.device))
         reg_soutput = self.inlier_model(reg_sinput)
         inlier_timer.toc()
 
@@ -395,8 +395,8 @@ class WeightedProcrustesTrainer:
       hit_ratio_meter.update(is_correct.sum().item() / len(is_correct))
 
       inlier_timer.tic()
-      reg_sinput = ME.SparseTensor(reg_feats.contiguous(),
-                                   coords=reg_coords.int()).to(self.device)
+      reg_sinput = ME.SparseTensor(reg_feats.contiguous().to(self.device),
+                                   coordinates=reg_coors.int().to(self.device))
       reg_soutput = self.inlier_model(reg_sinput)
       inlier_timer.toc()
 
@@ -630,10 +630,10 @@ class WeightedProcrustesTrainer:
   def generate_inlier_input(self, xyz0, xyz1, iC0, iC1, iF0, iF1, len_batch, pos_pairs):
     # pairs consist of (xyz1 index, xyz0 index)
     stime = time.time()
-    sinput0 = ME.SparseTensor(iF0, coords=iC0).to(self.device)
+    sinput0 = ME.SparseTensor(iF0.to(self.device), coordinates=iC0.to(self.device))
     oF0 = self.feat_model(sinput0).F
 
-    sinput1 = ME.SparseTensor(iF1, coords=iC1).to(self.device)
+    sinput1 = ME.SparseTensor(iF1.to(self.device), coordinates=iC1.to(self.device))
     oF1 = self.feat_model(sinput1).F
     feat_time = time.time() - stime
 
diff --git a/dataloader/kitti_loader.py b/dataloader/kitti_loader.py
index 3c14a8f..ca5fd7f 100644
--- a/dataloader/kitti_loader.py
+++ b/dataloader/kitti_loader.py
@@ -148,9 +148,9 @@ class KITTIPairDataset(PairDataset):
         xyz0_t = self.apply_transform(xyz0[sel0], M)
         pcd0 = make_open3d_point_cloud(xyz0_t)
         pcd1 = make_open3d_point_cloud(xyz1[sel1])
-        reg = o3d.registration.registration_icp(pcd0, pcd1, 0.2, np.eye(4),
-                                   o3d.registration.TransformationEstimationPointToPoint(),
-                                   o3d.registration.ICPConvergenceCriteria(max_iteration=200))
+        reg = o3d.pipelines.registration.registration_icp(pcd0, pcd1, 0.2, np.eye(4),
+                                   o3d.pipelines.registration.TransformationEstimationPointToPoint(),
+                                   o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=200))
         pcd0.transform(reg.transformation)
         # pcd0.transform(M2) or self.apply_transform(xyz0, M2)
         M2 = M @ reg.transformation
diff --git a/demo.py b/demo.py
index 604b5a1..4bfba45 100644
--- a/demo.py
+++ b/demo.py
@@ -5,12 +5,21 @@
 # - Christopher Choy, Jaesik Park, Vladlen Koltun, Fully Convolutional Geometric Features, ICCV 2019
 # - Christopher Choy, JunYoung Gwak, Silvio Savarese, 4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks, CVPR 2019
 import os
-from urllib.request import urlretrieve
+from urllib.request import urlopen
 
 import open3d as o3d
 from core.deep_global_registration import DeepGlobalRegistration
 from config import get_config
 
+import matplotlib.pyplot as plt
+
+import pfio
+import tempfile
+import contextlib
+from urllib.error import URLError, HTTPError, ContentTooShortError
+from urllib.parse import (splittype)
+from urllib.response import addinfourl, addclosehook
+
 BASE_URL = "http://node2.chrischoy.org/data/"
 DOWNLOAD_LIST = [
     (BASE_URL + "datasets/registration/", "redkitchen_000.ply"),
@@ -18,31 +27,40 @@ DOWNLOAD_LIST = [
     (BASE_URL + "projects/DGR/", "ResUNetBN2C-feat32-3dmatch-v0.05.pth")
 ]
 
-# Check if the weights and file exist and download
-if not os.path.isfile('redkitchen_000.ply'):
-  print('Downloading weights and pointcloud files...')
-  for f in DOWNLOAD_LIST:
-    print(f"Downloading {f}")
-    urlretrieve(f[0] + f[1], f[1])
-
 if __name__ == '__main__':
   config = get_config()
   if config.weights is None:
     config.weights = DOWNLOAD_LIST[-1][-1]
 
   # preprocessing
-  pcd0 = o3d.io.read_point_cloud(config.pcd0)
+  pcd0 = o3d.io.read_point_cloud("/mnt/vol21/i22_msbrf65/dataset/redkitchen_000.ply")
   pcd0.estimate_normals()
-  pcd1 = o3d.io.read_point_cloud(config.pcd1)
+  pcd1 = o3d.io.read_point_cloud("/mnt/vol21/i22_msbrf65/dataset/redkitchen_010.ply")
   pcd1.estimate_normals()
 
+  print("Read Data completed!")
+  config.weights = "/mnt/vol21/i22_msbrf65/weight/ResUNetBN2C-feat32-3dmatch-v0.05.pth"
+
   # registration
   dgr = DeepGlobalRegistration(config)
   T01 = dgr.register(pcd0, pcd1)
 
-  o3d.visualization.draw_geometries([pcd0, pcd1])
+  vis = o3d.visualization.Visualizer()
+  print("pcd0")
+  vis.add_geometry(pcd0)
+  print("pcd1")
+  vis.add_geometry(pcd1)
+  print("capture")
+  vis.capture_screen_screen_buffer(False)
+  print("save")
+  plt.imsave("/mnt/vol21/i22_msbrf65/dataset/before.png")
 
   pcd0.transform(T01)
   print(T01)
 
   o3d.visualization.draw_geometries([pcd0, pcd1])
+  vis = o3d.visualization.Visualizer()
+  vis.add_geometry(pcd0)
+  vis.add_geometry(pcd1)
+  vis.capture_screen_screen_buffer(False)
+  plt.imsave("/mnt/vol21/i22_msbrf65/dataset/after.png")
\ No newline at end of file
diff --git a/exec.sh b/exec.sh
index 84d9e31..4e54d45 100755
--- a/exec.sh
+++ b/exec.sh
@@ -1,5 +1,2 @@
 #!/bin/sh
-APPDIR=`dirname $0`
-pip install -r $APPDIR/requirements.txt --user
-
-python -u demo.py
+python -u /repo/demo.py
diff --git a/model/pyramidnet.py b/model/pyramidnet.py
index 8a0b9aa..3bd9798 100644
--- a/model/pyramidnet.py
+++ b/model/pyramidnet.py
@@ -15,7 +15,7 @@ from model.residual_block import get_block, conv, conv_tr, conv_norm_non
 class PyramidModule(ME.MinkowskiNetwork):
   NONLINEARITY = 'ELU'
   NORM_TYPE = 'BN'
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   def __init__(self,
                inc,
@@ -55,7 +55,7 @@ class PyramidModule(ME.MinkowskiNetwork):
             kernel_size=3,
             stride=2,
             dilation=1,
-            has_bias=False,
+            bias=False,
             region_type=self.REGION_TYPE,
             dimension=dimension),
         get_norm(
@@ -93,7 +93,7 @@ class PyramidNet(ME.MinkowskiNetwork):
   DEPTHS = [1, 1, 1, 1]
   # None        b1, b2, b3, btr3, btr2
   #               1  2  3 -3 -2 -1
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -157,8 +157,8 @@ class PyramidNet(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
diff --git a/model/residual_block.py b/model/residual_block.py
index f933be5..5565da9 100644
--- a/model/residual_block.py
+++ b/model/residual_block.py
@@ -17,14 +17,14 @@ def conv(in_channels,
          kernel_size=3,
          stride=1,
          dilation=1,
-         has_bias=False,
+         bias=False,
          region_type=0,
          dimension=3):
   if not isinstance(region_type, ME.RegionType):
     if region_type == 0:
-      region_type = ME.RegionType.HYPERCUBE
+      region_type = ME.RegionType.HYPER_CUBE
     elif region_type == 1:
-      region_type = ME.RegionType.HYPERCROSS
+      region_type = ME.RegionType.HYPER_CROSS
     else:
       raise ValueError('Unsupported region type')
 
@@ -49,8 +49,8 @@ def conv_tr(in_channels,
             kernel_size,
             stride=1,
             dilation=1,
-            has_bias=False,
-            region_type=ME.RegionType.HYPERCUBE,
+            bias=False,
+            region_type=ME.RegionType.HYPER_CUBE,
             dimension=-1):
   assert dimension > 0, 'Dimension must be a positive integer'
   kernel_generator = ME.KernelGenerator(
@@ -75,7 +75,7 @@ def conv_tr(in_channels,
       kernel_size=kernel_size,
       stride=stride,
       dilation=dilation,
-      has_bias=has_bias,
+      bias=bias,
       kernel_generator=kernel_generator,
       dimension=dimension)
 
@@ -174,7 +174,7 @@ def conv_norm_non(inc,
                   stride,
                   dimension,
                   bn_momentum=0.05,
-                  region_type=ME.RegionType.HYPERCUBE,
+                  region_type=ME.RegionType.HYPER_CUBE,
                   norm_type='BN',
                   nonlinearity='ELU'):
   return nn.Sequential(
@@ -184,7 +184,7 @@ def conv_norm_non(inc,
           kernel_size=kernel_size,
           stride=stride,
           dilation=1,
-          has_bias=False,
+          bias=False,
           region_type=region_type,
           dimension=dimension),
       get_norm(norm_type, outc, bn_momentum=bn_momentum, dimension=dimension),
diff --git a/model/resunet.py b/model/resunet.py
index 831517f..e6c7f35 100644
--- a/model/resunet.py
+++ b/model/resunet.py
@@ -18,7 +18,7 @@ class ResUNet(ME.MinkowskiNetwork):
   BLOCK_NORM_TYPE = 'BN'
   CHANNELS = [None, 32, 64, 128]
   TR_CHANNELS = [None, 32, 64, 64]
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -43,7 +43,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
 
@@ -61,7 +61,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
 
@@ -79,7 +79,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
 
@@ -97,7 +97,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -116,7 +116,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -135,7 +135,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
@@ -146,7 +146,7 @@ class ResUNet(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -185,8 +185,8 @@ class ResUNet(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -202,7 +202,7 @@ class ResUNetBNF(ResUNet):
 
 
 class ResUNetBNFX(ResUNetBNF):
-  REGION_TYPE = ME.RegionType.HYPERCROSS
+  REGION_TYPE = ME.RegionType.HYPER_CROSS
 
 
 class ResUNetSP(ME.MinkowskiNetwork):
@@ -213,7 +213,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
   # None        b1, b2, b3, btr3, btr2
   #               1  2  3 -3 -2 -1
   DEPTHS = [None, 1, 1, 1, 1, 1, None]
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -238,7 +238,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
@@ -260,7 +260,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
 
@@ -281,7 +281,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
 
@@ -302,7 +302,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -324,7 +324,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm2_tr = get_norm(
@@ -346,7 +346,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
 
@@ -358,7 +358,7 @@ class ResUNetSP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -402,14 +402,14 @@ class ResUNetSP(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
 
 class ResUNetBNSPC(ResUNetSP):
-  REGION_TYPE = ME.RegionType.HYPERCROSS
+  REGION_TYPE = ME.RegionType.HYPER_CROSS
 
 
 class ResUNetINBNSPC(ResUNetBNSPC):
@@ -421,7 +421,7 @@ class ResUNet2(ME.MinkowskiNetwork):
   BLOCK_NORM_TYPE = 'BN'
   CHANNELS = [None, 32, 64, 128, 256]
   TR_CHANNELS = [None, 32, 64, 64, 128]
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -445,7 +445,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
@@ -464,7 +464,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -483,7 +483,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -502,7 +502,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
@@ -521,7 +521,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm4_tr = get_norm(
@@ -541,7 +541,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm3_tr = get_norm(
@@ -561,7 +561,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm2_tr = get_norm(
@@ -581,7 +581,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
@@ -592,7 +592,7 @@ class ResUNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -643,8 +643,8 @@ class ResUNet2(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -666,7 +666,7 @@ class ResUNetBN2C(ResUNet2):
 
 
 class ResUNetBN2CX(ResUNetBN2C):
-  REGION_TYPE = ME.RegionType.HYPERCROSS
+  REGION_TYPE = ME.RegionType.HYPER_CROSS
 
 
 class ResUNetBN2D(ResUNet2):
@@ -688,7 +688,7 @@ class ResUNetBN2F(ResUNet2):
 
 
 class ResUNetBN2FX(ResUNetBN2F):
-  REGION_TYPE = ME.RegionType.HYPERCROSS
+  REGION_TYPE = ME.RegionType.HYPER_CROSS
 
 
 class ResUNet2v2(ME.MinkowskiNetwork):
@@ -699,7 +699,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
   # None        b1, b2, b3, b4, btr4, btr3, btr2
   #               1  2  3  4,-4,-3,-2,-1
   DEPTHS = [None, 1, 1, 1, 1, 1, 1, 1, None]
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -724,7 +724,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
 
@@ -743,7 +743,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
 
@@ -762,7 +762,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
 
@@ -781,7 +781,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
 
@@ -800,7 +800,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
@@ -820,7 +820,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -840,7 +840,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -860,7 +860,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
@@ -871,7 +871,7 @@ class ResUNet2v2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
     self.weight_initialization()
 
@@ -932,8 +932,8 @@ class ResUNet2v2(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -977,7 +977,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
   BLOCK_NORM_TYPE = 'BN'
   CHANNELS = [None, 32, 64, 128, 256]
   TR_CHANNELS = [None, 32, 64, 64, 128]
-  REGION_TYPE = ME.RegionType.HYPERCUBE
+  REGION_TYPE = ME.RegionType.HYPER_CUBE
 
   # To use the model, must call initialize_coords before forward pass.
   # Once data is processed, call clear to reset the model before calling initialize_coords
@@ -1001,8 +1001,8 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
-        region_type=ME.RegionType.HYPERCUBE,
+        bias=False,
+        region_type=ME.RegionType.HYPER_CUBE,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
 
@@ -1021,7 +1021,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -1041,7 +1041,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -1061,8 +1061,8 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=1,
         dilation=1,
-        has_bias=False,
-        region_type=ME.RegionType.HYPERCUBE,
+        bias=False,
+        region_type=ME.RegionType.HYPER_CUBE,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
 
@@ -1071,7 +1071,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         CHANNELS[4],
         CHANNELS[4],
         bn_momentum=bn_momentum,
-        region_type=ME.RegionType.HYPERCUBE,
+        region_type=ME.RegionType.HYPER_CUBE,
         dimension=D)
 
     self.conv4_tr = conv_tr(
@@ -1080,8 +1080,8 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
-        region_type=ME.RegionType.HYPERCUBE,
+        bias=False,
+        region_type=ME.RegionType.HYPER_CUBE,
         dimension=D)
     self.norm4_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
@@ -1100,7 +1100,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm3_tr = get_norm(
@@ -1120,7 +1120,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         region_type=REGION_TYPE,
         dimension=D)
     self.norm2_tr = get_norm(
@@ -1140,7 +1140,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
 
     # self.block1_tr = BasicBlockBN(TR_CHANNELS[1], TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
@@ -1151,7 +1151,7 @@ class ResUNet2SP(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -1205,8 +1205,8 @@ class ResUNet2SP(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / (torch.norm(out.F, p=2, dim=1, keepdim=True) + 1e-8),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -1218,4 +1218,4 @@ class ResUNetBN2SPC(ResUNet2SP):
 
 
 class ResUNetBN2SPCX(ResUNetBN2SPC):
-  REGION_TYPE = ME.RegionType.HYPERCROSS
+  REGION_TYPE = ME.RegionType.HYPER_CROSS
diff --git a/model/simpleunet.py b/model/simpleunet.py
index 59ee1f7..4aabc0c 100644
--- a/model/simpleunet.py
+++ b/model/simpleunet.py
@@ -35,7 +35,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, D=D)
 
@@ -45,7 +45,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -55,7 +55,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -65,7 +65,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, D=D)
 
@@ -75,7 +75,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2_tr = get_norm(NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, D=D)
 
@@ -85,7 +85,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1_tr = get_norm(NORM_TYPE, TR_CHANNELS[1], bn_momentum=bn_momentum, D=D)
 
@@ -95,7 +95,7 @@ class SimpleNet(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -131,8 +131,8 @@ class SimpleNet(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -179,7 +179,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
 
@@ -189,7 +189,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
 
@@ -199,7 +199,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
 
@@ -209,7 +209,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
 
@@ -219,7 +219,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
@@ -230,7 +230,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -241,7 +241,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -252,7 +252,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
@@ -263,7 +263,7 @@ class SimpleNet2(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -309,8 +309,8 @@ class SimpleNet2(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
@@ -376,7 +376,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=conv1_kernel_size,
         stride=1,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm1 = get_norm(NORM_TYPE, CHANNELS[1], bn_momentum=bn_momentum, dimension=D)
 
@@ -386,7 +386,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2 = get_norm(NORM_TYPE, CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
 
@@ -396,7 +396,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3 = get_norm(NORM_TYPE, CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
 
@@ -406,7 +406,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4 = get_norm(NORM_TYPE, CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
 
@@ -416,7 +416,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm5 = get_norm(NORM_TYPE, CHANNELS[5], bn_momentum=bn_momentum, dimension=D)
 
@@ -426,7 +426,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm5_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[5], bn_momentum=bn_momentum, dimension=D)
@@ -437,7 +437,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm4_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[4], bn_momentum=bn_momentum, dimension=D)
@@ -448,7 +448,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm3_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[3], bn_momentum=bn_momentum, dimension=D)
@@ -459,7 +459,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=3,
         stride=2,
         dilation=1,
-        has_bias=False,
+        bias=False,
         dimension=D)
     self.norm2_tr = get_norm(
         NORM_TYPE, TR_CHANNELS[2], bn_momentum=bn_momentum, dimension=D)
@@ -470,7 +470,7 @@ class SimpleNet3(ME.MinkowskiNetwork):
         kernel_size=1,
         stride=1,
         dilation=1,
-        has_bias=True,
+        bias=True,
         dimension=D)
 
   def forward(self, x):
@@ -522,8 +522,8 @@ class SimpleNet3(ME.MinkowskiNetwork):
     if self.normalize_feature:
       return ME.SparseTensor(
           out.F / torch.norm(out.F, p=2, dim=1, keepdim=True),
-          coords_key=out.coords_key,
-          coords_manager=out.coords_man)
+          coordinate_map_key=out.coordinate_map_key,
+          coordinate_manager=out.coordinate_manager)
     else:
       return out
 
diff --git a/util/pointcloud.py b/util/pointcloud.py
index 3e5ee9c..c060015 100644
--- a/util/pointcloud.py
+++ b/util/pointcloud.py
@@ -23,7 +23,7 @@ def make_open3d_point_cloud(xyz, color=None):
 
 
 def make_open3d_feature(data, dim, npts):
-  feature = o3d.registration.Feature()
+  feature = o3d.pipelines.registration.Feature()
   feature.resize(dim, npts)
   feature.data = data.cpu().numpy().astype('d').transpose()
   return feature
@@ -33,7 +33,7 @@ def make_open3d_feature_from_numpy(data):
   assert isinstance(data, np.ndarray)
   assert data.ndim == 2
 
-  feature = o3d.registration.Feature()
+  feature = o3d.pipelines.registration.Feature()
   feature.resize(data.shape[1], data.shape[0])
   feature.data = data.astype('d').transpose()
   return feature
